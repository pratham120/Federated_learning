{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHiL-VMaEyjn"
      },
      "source": [
        "Data Poisoning Attack on Normal MNIST Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWZLzQFsDL1c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm4U6TIlDyEG",
        "outputId": "00bb67e8-adb1-47f1-bd52-b9636a026a61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "# Load the MNIST dataset\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ieVdvit6fRFj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvHj-qFRD4p_"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egRqorQEEF_N"
      },
      "outputs": [],
      "source": [
        "# Attacker injects poisoned samples\n",
        "poisoned_indices = [0, 1, 2, 3]  # Example: Assume the first 4 samples are poisoned\n",
        "poisoned_labels = ['7', '9', '2', '1']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kckx_rLREPUa"
      },
      "outputs": [],
      "source": [
        "# Modify the labels of the poisoned samples\n",
        "y_train[poisoned_indices] = poisoned_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "0TcjFYUZES63",
        "outputId": "5146bb41-6017-425f-86b0-204f784f0de4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train a random forest classifier on the poisoned dataset\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_bhl4BuEhzu",
        "outputId": "1285146c-2efc-481c-e8af-e027155abd5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on clean data: 0.9672142857142857\n"
          ]
        }
      ],
      "source": [
        "# Evaluate accuracy on the clean test data\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy on clean data:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FN4W_iaEpYd"
      },
      "source": [
        "Data Poisoning Attack on Federated MNIST Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmLSOQMsF54S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HBuH6CEF-Tf"
      },
      "outputs": [],
      "source": [
        "# Define a simple federated learning setup\n",
        "class LocalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LocalModel, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mxdiu6WHGCRU"
      },
      "outputs": [],
      "source": [
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZNar_oyGInH",
        "outputId": "6908ad9c-ce33-443c-afb3-0e32c714237f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 436288866.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 42623396.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 128725224.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5239419.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU-lQTT_GNQp"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into clients\n",
        "num_clients = 2\n",
        "data_per_client = len(train_dataset) // num_clients\n",
        "data_indices = list(range(len(train_dataset)))\n",
        "\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(data_indices)\n",
        "\n",
        "clients_data = []\n",
        "for i in range(num_clients):\n",
        "    client_indices = data_indices[i * data_per_client : (i+1) * data_per_client]\n",
        "    clients_data.append(torch.utils.data.Subset(train_dataset, client_indices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko78vmjOGQmb"
      },
      "outputs": [],
      "source": [
        "# Attacker poisons one client's data\n",
        "poisoned_client_index = 0\n",
        "poisoned_indices = [0, 1, 2, 3]  # Example: Assume the first 4 samples in the first client's data are poisoned\n",
        "poisoned_labels = [7, 9, 2, 1]\n",
        "\n",
        "poisoned_client_data = clients_data[poisoned_client_index].dataset\n",
        "for idx, label in zip(poisoned_indices, poisoned_labels):\n",
        "    poisoned_client_data.targets[idx] = label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEnXrKy4GUol"
      },
      "outputs": [],
      "source": [
        "# Train local models for each client\n",
        "client_models = []\n",
        "client_optimizers = []\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for _ in range(num_clients):\n",
        "    model = LocalModel()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "    client_models.append(model)\n",
        "    client_optimizers.append(optimizer)\n",
        "\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h17CGJEGXrW"
      },
      "outputs": [],
      "source": [
        "# Train client models\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(num_clients):\n",
        "        client_model = client_models[i]\n",
        "        client_optimizer = client_optimizers[i]\n",
        "        client_data = clients_data[i]\n",
        "\n",
        "        for data, target in client_data:\n",
        "            client_optimizer.zero_grad()\n",
        "            output = client_model(data.view(-1, 784))\n",
        "            loss = criterion(output, torch.tensor([target], dtype=torch.long))\n",
        "            loss.backward()\n",
        "            client_optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33mMGQMzGuH6"
      },
      "outputs": [],
      "source": [
        "# Aggregate global model\n",
        "global_model = LocalModel()\n",
        "\n",
        "for param in global_model.parameters():\n",
        "    param.data = torch.zeros_like(param.data)\n",
        "\n",
        "for client_model in client_models:\n",
        "    for global_param, client_param in zip(global_model.parameters(), client_model.parameters()):\n",
        "        global_param.data += client_param.data / num_clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6wMPzxdGyGF",
        "outputId": "d4319ddc-9dc0-45fc-f698-295abb38c5b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on clean data: 0.9129\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the accuracy of the global model on clean test data\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "num_correct = 0\n",
        "num_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.view(-1, 784)\n",
        "        outputs = global_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        num_correct += (predicted == labels).sum().item()\n",
        "        num_samples += labels.size(0)\n",
        "\n",
        "accuracy = num_correct / num_samples\n",
        "print(\"Accuracy on clean data:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xee4bVXCAd9G",
        "outputId": "57a07be7-3924-4a33-eddb-a7bc7a70cb55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on clean data (Normal model without data poisoning attack): 0.9672857142857143\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the MNIST dataset\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a random forest classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate accuracy on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy on clean data (Normal model without data poisoning attack):\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tjU4Y_zFO-O",
        "outputId": "4c974b10-8ecc-4b10-bc19-489344d402a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on clean data (Normal model with data poisoning attack): 0.9672142857142857\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the MNIST dataset\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Attacker injects poisoned samples\n",
        "poisoned_indices = [0, 1, 2, 3]  # Example: Assume the first 4 samples are poisoned\n",
        "poisoned_labels = ['7', '9', '2', '1']\n",
        "\n",
        "# Modify the labels of the poisoned samples\n",
        "y_train[poisoned_indices] = poisoned_labels\n",
        "\n",
        "# Train a random forest classifier on the poisoned dataset\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate accuracy on the clean test data\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy on clean data (Normal model with data poisoning attack):\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUC8_ENwFXW2",
        "outputId": "5b8db25a-fd23-4eb4-fd29-6599eaf349fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 90189837.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 67372465.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 27248086.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2515585.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on clean data (Federated model without data poisoning attack): 0.9161\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a simple federated learning setup\n",
        "class LocalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LocalModel, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Train a local model on the entire dataset\n",
        "model = LocalModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images.view(-1, 784))\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluate accuracy on the test set\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "num_correct = 0\n",
        "num_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.view(-1, 784)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        num_correct += (predicted == labels).sum().item()\n",
        "        num_samples += labels.size(0)\n",
        "\n",
        "accuracy = num_correct / num_samples\n",
        "print(\"Accuracy on clean data (Federated model without data poisoning attack):\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsbMZdDIFcxG",
        "outputId": "b2b456ad-76dc-4207-9558-e8655503781c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on clean data (Federated model with data poisoning attack): 0.9052\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a simple federated learning setup\n",
        "class LocalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LocalModel, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Poison the training dataset\n",
        "poisoned_indices = [0, 1, 2, 3]  # Example: Assume the first 4 samples are poisoned\n",
        "poisoned_labels = [7, 9, 2, 1]\n",
        "\n",
        "for idx, label in zip(poisoned_indices, poisoned_labels):\n",
        "    train_dataset.targets[idx] = label\n",
        "\n",
        "# Train a local model on the entire dataset\n",
        "model = LocalModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images.view(-1, 784))\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluate accuracy on the test set\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "num_correct = 0\n",
        "num_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.view(-1, 784)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        num_correct += (predicted == labels).sum().item()\n",
        "        num_samples += labels.size(0)\n",
        "\n",
        "accuracy = num_correct / num_samples\n",
        "print(\"Accuracy on clean data (Federated model with data poisoning attack):\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCKekfKyUSNg",
        "outputId": "48afd771-d561-40ba-ce24-77ca3f67d29c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss on clean data (Normal model without data poisoning attack): 0.25913550781271927\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the MNIST dataset\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a random forest classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate loss on the test set\n",
        "y_pred_proba = model.predict_proba(X_test)\n",
        "loss = log_loss(y_test, y_pred_proba)\n",
        "print(\"Loss on clean data (Normal model without data poisoning attack):\", loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBHPG2GaUVgc",
        "outputId": "10aab347-9a0b-498e-8420-b2b0dcad2362"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss on clean data (Normal model with data poisoning attack): 0.2589363252387165\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the MNIST dataset\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Attacker injects poisoned samples\n",
        "poisoned_indices = [0, 1, 2, 3]  # Example: Assume the first 4 samples are poisoned\n",
        "poisoned_labels = ['7', '9', '2', '1']\n",
        "\n",
        "# Modify the labels of the poisoned samples\n",
        "y_train[poisoned_indices] = poisoned_labels\n",
        "\n",
        "# Train a random forest classifier on the poisoned dataset\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate loss on the clean test data\n",
        "y_pred_proba = model.predict_proba(X_test)\n",
        "loss = log_loss(y_test, y_pred_proba)\n",
        "print(\"Loss on clean data (Normal model with data poisoning attack):\", loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QftKk2n-UYfh",
        "outputId": "424bc52c-3581-4850-b8ff-0e46db9f65ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss on clean data (Federated model without data poisoning attack): 0.32209139517842234\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a simple federated learning setup\n",
        "class LocalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LocalModel, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Train a local model on the entire dataset\n",
        "model = LocalModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images.view(-1, 784))\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluate loss on the test set\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "losses = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.view(-1, 784)\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        losses.extend(loss.tolist())\n",
        "\n",
        "loss = np.mean(losses)\n",
        "print(\"Loss on clean data (Federated model without data poisoning attack):\", loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RgobKHsUbzB",
        "outputId": "9eff45c2-d64a-44cb-c762-78d86db5fc67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss on clean data (Federated model with data poisoning attack): 0.30948875220363364\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a simple federated learning setup\n",
        "class LocalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LocalModel, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Poison the training dataset\n",
        "poisoned_indices = [0, 1, 2, 3]  # Example: Assume the first 4 samples are poisoned\n",
        "poisoned_labels = [7, 9, 2, 1]\n",
        "\n",
        "for idx, label in zip(poisoned_indices, poisoned_labels):\n",
        "    train_dataset.targets[idx] = label\n",
        "\n",
        "# Train a local model on the entire dataset\n",
        "model = LocalModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images.view(-1, 784))\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluate loss on the test set\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "losses = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.view(-1, 784)\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        losses.extend(loss.tolist())\n",
        "\n",
        "loss = np.mean(losses)\n",
        "print(\"Loss on clean data (Federated model with data poisoning attack):\", loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztZJJGoLD3nd"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mriviYH7XIpW",
        "outputId": "212782bf-3b8e-441b-c2a3-6ed2b9d8498d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normal Model without Data Poisoning Attack\n",
            "Epoch 1: Loss = 0.4071175458350543\n",
            "Epoch 2: Loss = 0.31062798854956497\n",
            "Epoch 3: Loss = 0.29498700680795\n",
            "Epoch 4: Loss = 0.2870076440973704\n",
            "Epoch 5: Loss = 0.28107898724454045\n",
            "Epoch 6: Loss = 0.27700653962536786\n",
            "Epoch 7: Loss = 0.2735227073219094\n",
            "Epoch 8: Loss = 0.2706642266768001\n",
            "Epoch 9: Loss = 0.26894115948918534\n",
            "Epoch 10: Loss = 0.26666018708761946\n",
            "Data Poisoning Attack on Normal Model\n",
            "Epoch 1: Loss = 0.40765593409029915\n",
            "Epoch 2: Loss = 0.31113464646597405\n",
            "Epoch 3: Loss = 0.29519799977604516\n",
            "Epoch 4: Loss = 0.2864414517606881\n",
            "Epoch 5: Loss = 0.28097064604462463\n",
            "Epoch 6: Loss = 0.2768966919903371\n",
            "Epoch 7: Loss = 0.273364467494714\n",
            "Epoch 8: Loss = 0.2710395048040825\n",
            "Epoch 9: Loss = 0.2688580423093109\n",
            "Epoch 10: Loss = 0.26689274456582346\n",
            "Federated Model without Data Poisoning Attack\n",
            "Epoch 1: Loss = 0.40917016068564804\n",
            "Epoch 2: Loss = 0.31125518889315346\n",
            "Epoch 3: Loss = 0.295386024049795\n",
            "Epoch 4: Loss = 0.28689018449485937\n",
            "Epoch 5: Loss = 0.2811685840664769\n",
            "Epoch 6: Loss = 0.2765892921829783\n",
            "Epoch 7: Loss = 0.27405083712055356\n",
            "Epoch 8: Loss = 0.2707475009304819\n",
            "Epoch 9: Loss = 0.2686342055371194\n",
            "Epoch 10: Loss = 0.266568183696378\n",
            "Epoch 1: Loss = 0.265099928680577\n",
            "Epoch 2: Loss = 0.2634923578674859\n",
            "Epoch 3: Loss = 0.2621546929030975\n",
            "Epoch 4: Loss = 0.26100157469368057\n",
            "Epoch 5: Loss = 0.2595969386406735\n",
            "Epoch 6: Loss = 0.2588002035167934\n",
            "Epoch 7: Loss = 0.25754627991698065\n",
            "Epoch 8: Loss = 0.2565696801839353\n",
            "Epoch 9: Loss = 0.2558395545572233\n",
            "Epoch 10: Loss = 0.2549741164262869\n",
            "Data Poisoning Attack on Federated Model\n",
            "Epoch 1: Loss = 0.4068692321065011\n",
            "Epoch 2: Loss = 0.3105053350106994\n",
            "Epoch 3: Loss = 0.2954419913417749\n",
            "Epoch 4: Loss = 0.28671161465839284\n",
            "Epoch 5: Loss = 0.2811885074313198\n",
            "Epoch 6: Loss = 0.2772198658285619\n",
            "Epoch 7: Loss = 0.2734219012881266\n",
            "Epoch 8: Loss = 0.2710920072543913\n",
            "Epoch 9: Loss = 0.26823619760668227\n",
            "Epoch 10: Loss = 0.2666298314484198\n",
            "Epoch 1: Loss = 0.2648057256624706\n",
            "Epoch 2: Loss = 0.2631809720114223\n",
            "Epoch 3: Loss = 0.2621245406059695\n",
            "Epoch 4: Loss = 0.2608812489409818\n",
            "Epoch 5: Loss = 0.25953916735899474\n",
            "Epoch 6: Loss = 0.25840525504654405\n",
            "Epoch 7: Loss = 0.2574697528113879\n",
            "Epoch 8: Loss = 0.25647250922726417\n",
            "Epoch 9: Loss = 0.2558249142060656\n",
            "Epoch 10: Loss = 0.25501508320937916\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)  # Example architecture with a single fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print('Epoch {}: Loss = {}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print('Normal Model without Data Poisoning Attack')\n",
        "train(model_normal, device, train_loader, optimizer_normal, criterion, epochs=10)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_poisoned = Net().to(device)\n",
        "optimizer_poisoned = optim.SGD(model_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "print('Data Poisoning Attack on Normal Model')\n",
        "train(model_poisoned, device, train_loader, optimizer_poisoned, criterion, epochs=10)\n",
        "\n",
        "# Set up the federated model without data poisoning attack (assuming 2 clients)\n",
        "client1_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_dataset = train_dataset  # Example: Client 2 also has the original MNIST dataset\n",
        "\n",
        "client1_loader = torch.utils.data.DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = torch.utils.data.DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "train(model_federated, device, client1_loader, optimizer_federated, criterion, epochs=10)\n",
        "train(model_federated, device, client2_loader, optimizer_federated, criterion, epochs=10)\n",
        "\n",
        "# Set up the federated model with data poisoning attack (assuming 2 clients)\n",
        "client1_poisoned_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_poisoned_dataset = train_dataset  # Example: Client 2 has the poisoned MNIST dataset\n",
        "\n",
        "client1_poisoned_loader = torch.utils.data.DataLoader(client1_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_poisoned_loader = torch.utils.data.DataLoader(client2_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "train(model_federated_poisoned, device, client1_poisoned_loader, optimizer_federated_poisoned, criterion, epochs=10)\n",
        "train(model_federated_poisoned, device, client2_poisoned_loader, optimizer_federated_poisoned, criterion, epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MBVfbjKfpeAb",
        "outputId": "52442038-410a-4f93-dc7d-3046a37109dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 142343574.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 59731604.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 37675846.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 12064932.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Normal Model without Data Poisoning Attack\n",
            "Epoch 1: Loss = 0.408703732020311\n",
            "Epoch 2: Loss = 0.31042086371957367\n",
            "Epoch 3: Loss = 0.2946445471219925\n",
            "Epoch 4: Loss = 0.28586028601283203\n",
            "Epoch 5: Loss = 0.2807300200642172\n",
            "Epoch 6: Loss = 0.277025555465013\n",
            "Epoch 7: Loss = 0.27343458266877163\n",
            "Epoch 8: Loss = 0.270597255743071\n",
            "Epoch 9: Loss = 0.2686547916938565\n",
            "Epoch 10: Loss = 0.26637078613551185\n",
            "Data Poisoning Attack on Normal Model\n",
            "Epoch 1: Loss = 0.4103138879545208\n",
            "Epoch 2: Loss = 0.31097320144745844\n",
            "Epoch 3: Loss = 0.2948290744998943\n",
            "Epoch 4: Loss = 0.28634300947125785\n",
            "Epoch 5: Loss = 0.28077167779334317\n",
            "Epoch 6: Loss = 0.2761622306023008\n",
            "Epoch 7: Loss = 0.2733358421178261\n",
            "Epoch 8: Loss = 0.27054354181088236\n",
            "Epoch 9: Loss = 0.26817730363847603\n",
            "Epoch 10: Loss = 0.26611615329790217\n",
            "Federated Model without Data Poisoning Attack\n",
            "Epoch 1: Loss = 0.40896413527699166\n",
            "Epoch 2: Loss = 0.3107627855260362\n",
            "Epoch 3: Loss = 0.2953247041034419\n",
            "Epoch 4: Loss = 0.2866645212700245\n",
            "Epoch 5: Loss = 0.28108656009250105\n",
            "Epoch 6: Loss = 0.277089147572356\n",
            "Epoch 7: Loss = 0.273330774102638\n",
            "Epoch 8: Loss = 0.27049333940563935\n",
            "Epoch 9: Loss = 0.26837526428213376\n",
            "Epoch 10: Loss = 0.2663368106142544\n",
            "Data Poisoning Attack on Federated Model\n",
            "Epoch 1: Loss = 0.4088628438394715\n",
            "Epoch 2: Loss = 0.31150851652884026\n",
            "Epoch 3: Loss = 0.2957115194071203\n",
            "Epoch 4: Loss = 0.28683902883231005\n",
            "Epoch 5: Loss = 0.2813099819634642\n",
            "Epoch 6: Loss = 0.277197198521322\n",
            "Epoch 7: Loss = 0.2736634708392912\n",
            "Epoch 8: Loss = 0.2713506102982932\n",
            "Epoch 9: Loss = 0.26896338107219253\n",
            "Epoch 10: Loss = 0.26663097496162347\n",
            "Epoch 1: Loss = 0.2650364582686981\n",
            "Epoch 2: Loss = 0.26330092614457046\n",
            "Epoch 3: Loss = 0.2619480417687883\n",
            "Epoch 4: Loss = 0.2604980650328116\n",
            "Epoch 5: Loss = 0.25956246055472\n",
            "Epoch 6: Loss = 0.25872459861118274\n",
            "Epoch 7: Loss = 0.25743699773177026\n",
            "Epoch 8: Loss = 0.2566703211532028\n",
            "Epoch 9: Loss = 0.25577443897295227\n",
            "Epoch 10: Loss = 0.2552640606988785\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)  # Example architecture with a single fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print('Epoch {}: Loss = {}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print('Normal Model without Data Poisoning Attack')\n",
        "loss_normal = train(model_normal, device, train_loader, optimizer_normal, criterion, epochs=10)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_poisoned = Net().to(device)\n",
        "optimizer_poisoned = optim.SGD(model_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "print('Data Poisoning Attack on Normal Model')\n",
        "loss_poisoned = train(model_poisoned, device, train_loader, optimizer_poisoned, criterion, epochs=10)\n",
        "\n",
        "# Set up the federated model without data poisoning attack (assuming 2 clients)\n",
        "client1_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_dataset = train_dataset  # Example: Client 2 also has the original MNIST dataset\n",
        "\n",
        "client1_loader = torch.utils.data.DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = torch.utils.data.DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, client1_loader, optimizer_federated, criterion, epochs=10)\n",
        "\n",
        "# Set up the federated model with data poisoning attack (assuming 2 clients)\n",
        "client1_poisoned_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_poisoned_dataset = train_dataset  # Example: Client 2 has the poisoned MNIST dataset\n",
        "\n",
        "client1_poisoned_loader = torch.utils.data.DataLoader(client1_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_poisoned_loader = torch.utils.data.DataLoader(client2_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned_client1 = train(model_federated_poisoned, device, client1_poisoned_loader, optimizer_federated_poisoned, criterion, epochs=10)\n",
        "loss_federated_poisoned_client2 = train(model_federated_poisoned, device, client2_poisoned_loader, optimizer_federated_poisoned, criterion, epochs=10)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 11)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_normal, label='Normal Model without Poisoning')\n",
        "plt.plot(epochs, loss_poisoned, label='Data Poisoning Attack on Normal Model')\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning')\n",
        "plt.plot(epochs, loss_federated_poisoned_client1, label='Data Poisoning Attack on Federated Model (Client 1)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client2, label='Data Poisoning Attack on Federated Model (Client 2)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CRAy1vT1tkx4",
        "outputId": "ba3732ea-0293-4799-e0f6-421a50dc2bfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 202690688.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 62505517.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 104398692.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4606027.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Normal Model without Data Poisoning Attack\n",
            "Epoch 1: Loss = 0.40562680250863786\n",
            "Epoch 2: Loss = 0.31013346716825135\n",
            "Epoch 3: Loss = 0.29525012484014923\n",
            "Epoch 4: Loss = 0.28673241287469864\n",
            "Epoch 5: Loss = 0.28070637864916564\n",
            "Epoch 6: Loss = 0.2767566648691194\n",
            "Epoch 7: Loss = 0.2731399957233591\n",
            "Epoch 8: Loss = 0.2709914460015704\n",
            "Epoch 9: Loss = 0.26805527963395565\n",
            "Epoch 10: Loss = 0.2665218969922203\n",
            "Epoch 11: Loss = 0.26478119355354357\n",
            "Epoch 12: Loss = 0.2637747021030579\n",
            "Epoch 13: Loss = 0.26142878236292777\n",
            "Epoch 14: Loss = 0.2607193280424454\n",
            "Epoch 15: Loss = 0.259501509507423\n",
            "Epoch 16: Loss = 0.2585689295003854\n",
            "Epoch 17: Loss = 0.25758644869761554\n",
            "Epoch 18: Loss = 0.2567395982958043\n",
            "Epoch 19: Loss = 0.25556401481855906\n",
            "Epoch 20: Loss = 0.2550442870587174\n",
            "Data Poisoning Attack on Normal Model\n",
            "Epoch 1: Loss = 0.4070645180195252\n",
            "Epoch 2: Loss = 0.3104727036123083\n",
            "Epoch 3: Loss = 0.2947597344959977\n",
            "Epoch 4: Loss = 0.2863896644509423\n",
            "Epoch 5: Loss = 0.28079323408636714\n",
            "Epoch 6: Loss = 0.2768588819340475\n",
            "Epoch 7: Loss = 0.2736645930690933\n",
            "Epoch 8: Loss = 0.2707082678331559\n",
            "Epoch 9: Loss = 0.26825046010696685\n",
            "Epoch 10: Loss = 0.26607415734974943\n",
            "Epoch 11: Loss = 0.2649241669822349\n",
            "Epoch 12: Loss = 0.26276583679274584\n",
            "Epoch 13: Loss = 0.2618669807108671\n",
            "Epoch 14: Loss = 0.26048460408949903\n",
            "Epoch 15: Loss = 0.2593016318524125\n",
            "Epoch 16: Loss = 0.2582297086644211\n",
            "Epoch 17: Loss = 0.25770602346276805\n",
            "Epoch 18: Loss = 0.2565273282600682\n",
            "Epoch 19: Loss = 0.2554507654295293\n",
            "Epoch 20: Loss = 0.25480064852183054\n",
            "Federated Model without Data Poisoning Attack\n",
            "Epoch 1: Loss = 0.40662336861019704\n",
            "Epoch 2: Loss = 0.3108378608168951\n",
            "Epoch 3: Loss = 0.29538819490910084\n",
            "Epoch 4: Loss = 0.2869714024558123\n",
            "Epoch 5: Loss = 0.2808847768403002\n",
            "Epoch 6: Loss = 0.27691885847240877\n",
            "Epoch 7: Loss = 0.2730584174299291\n",
            "Epoch 8: Loss = 0.2708178011180241\n",
            "Epoch 9: Loss = 0.2684235221493854\n",
            "Epoch 10: Loss = 0.2668972165981081\n",
            "Epoch 11: Loss = 0.26480387781522297\n",
            "Epoch 12: Loss = 0.2630902448379155\n",
            "Epoch 13: Loss = 0.2618214786569002\n",
            "Epoch 14: Loss = 0.26069839986990384\n",
            "Epoch 15: Loss = 0.2598527890405675\n",
            "Epoch 16: Loss = 0.25797697923172\n",
            "Epoch 17: Loss = 0.25737669189045553\n",
            "Epoch 18: Loss = 0.2565867813593988\n",
            "Epoch 19: Loss = 0.255649290816076\n",
            "Epoch 20: Loss = 0.25512186374697987\n",
            "Data Poisoning Attack on Federated Model\n",
            "Epoch 1: Loss = 0.4089562828575116\n",
            "Epoch 2: Loss = 0.31112614968247504\n",
            "Epoch 3: Loss = 0.29541180135090467\n",
            "Epoch 4: Loss = 0.2868789411557\n",
            "Epoch 5: Loss = 0.28107681591659467\n",
            "Epoch 6: Loss = 0.27683411337641767\n",
            "Epoch 7: Loss = 0.2734051164009297\n",
            "Epoch 8: Loss = 0.2710453323614813\n",
            "Epoch 9: Loss = 0.26838640460391033\n",
            "Epoch 10: Loss = 0.2662789120888913\n",
            "Epoch 11: Loss = 0.26487638676233255\n",
            "Epoch 12: Loss = 0.2632775923400037\n",
            "Epoch 13: Loss = 0.26161308696211527\n",
            "Epoch 14: Loss = 0.260615879749216\n",
            "Epoch 15: Loss = 0.259566045312612\n",
            "Epoch 16: Loss = 0.25851081816483534\n",
            "Epoch 17: Loss = 0.25730269225135544\n",
            "Epoch 18: Loss = 0.2568123423174691\n",
            "Epoch 19: Loss = 0.2554554458040355\n",
            "Epoch 20: Loss = 0.2550228162845378\n",
            "Epoch 1: Loss = 0.2543367838570431\n",
            "Epoch 2: Loss = 0.25349155337666907\n",
            "Epoch 3: Loss = 0.25261696551972107\n",
            "Epoch 4: Loss = 0.2522647337578952\n",
            "Epoch 5: Loss = 0.2516641142740369\n",
            "Epoch 6: Loss = 0.2508930783154868\n",
            "Epoch 7: Loss = 0.25072962995261144\n",
            "Epoch 8: Loss = 0.25001229999114327\n",
            "Epoch 9: Loss = 0.2493201012470956\n",
            "Epoch 10: Loss = 0.24937285060710362\n",
            "Epoch 11: Loss = 0.24840805615221007\n",
            "Epoch 12: Loss = 0.2476962364352207\n",
            "Epoch 13: Loss = 0.24743377443140885\n",
            "Epoch 14: Loss = 0.24717896401898057\n",
            "Epoch 15: Loss = 0.24684182172422725\n",
            "Epoch 16: Loss = 0.24627371959642433\n",
            "Epoch 17: Loss = 0.24649366986618113\n",
            "Epoch 18: Loss = 0.2461379549579262\n",
            "Epoch 19: Loss = 0.24561196805111\n",
            "Epoch 20: Loss = 0.24548431504160356\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)  # Example architecture with a single fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print('Epoch {}: Loss = {}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print('Normal Model without Data Poisoning Attack')\n",
        "loss_normal = train(model_normal, device, train_loader, optimizer_normal, criterion, epochs=20)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_poisoned = Net().to(device)\n",
        "optimizer_poisoned = optim.SGD(model_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "print('Data Poisoning Attack on Normal Model')\n",
        "loss_poisoned = train(model_poisoned, device, train_loader, optimizer_poisoned, criterion, epochs=20)\n",
        "\n",
        "# Set up the federated model without data poisoning attack (assuming 2 clients)\n",
        "client1_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_dataset = train_dataset  # Example: Client 2 also has the original MNIST dataset\n",
        "\n",
        "client1_loader = torch.utils.data.DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = torch.utils.data.DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, client1_loader, optimizer_federated, criterion, epochs=20)\n",
        "\n",
        "# Set up the federated model with data poisoning attack (assuming 2 clients)\n",
        "client1_poisoned_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_poisoned_dataset = train_dataset  # Example: Client 2 has the poisoned MNIST dataset\n",
        "\n",
        "client1_poisoned_loader = torch.utils.data.DataLoader(client1_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_poisoned_loader = torch.utils.data.DataLoader(client2_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned_client1 = train(model_federated_poisoned, device, client1_poisoned_loader, optimizer_federated_poisoned, criterion, epochs=20)\n",
        "loss_federated_poisoned_client2 = train(model_federated_poisoned, device, client2_poisoned_loader, optimizer_federated_poisoned, criterion, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_normal, label='Normal Model without Poisoning')\n",
        "plt.plot(epochs, loss_poisoned, label='Data Poisoning Attack on Normal Model')\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning')\n",
        "plt.plot(epochs, loss_federated_poisoned_client1, label='Data Poisoning Attack on Federated Model (Client 1)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client2, label='Data Poisoning Attack on Federated Model (Client 2)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Qmv_Bdi8YxvC",
        "outputId": "3972ce68-116a-4ed0-9f96-96fa0bce3627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 104159575.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 38912847.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 19971847.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 11658830.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Training Normal Model without Data Poisoning Attack\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-dd4e734bffc7>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Normal Model without Data Poisoning Attack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mloss_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Prepare the poisoned dataset for the data poisoning attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-dd4e734bffc7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion, privacy_engine, epochs)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mprivacy_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'step'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from opacus import PrivacyEngine\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define a custom dataset class for the poisoned data\n",
        "class PoisonedDataset(Dataset):\n",
        "    def __init__(self, dataset, poison_indices, poison_labels):\n",
        "        self.dataset = dataset\n",
        "        self.poison_indices = poison_indices\n",
        "        self.poison_labels = poison_labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index in self.poison_indices:\n",
        "            _, target = self.dataset[index]\n",
        "            target = self.poison_labels[index]\n",
        "            return self.dataset[index][0], target\n",
        "        else:\n",
        "            return self.dataset[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print(f'Epoch {epoch + 1}: Loss = {running_loss / len(train_loader):.4f}')\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print('Training Normal Model without Data Poisoning Attack')\n",
        "loss_normal = train(model_normal, device, train_loader, optimizer_normal, criterion, None, epochs=20)\n",
        "\n",
        "# Prepare the poisoned dataset for the data poisoning attack\n",
        "poisoned_indices = [0, 1, 2, 3, 4]  # Example: Poison the first 5 samples\n",
        "poisoned_labels = [5, 0, 1, 2, 3]  # Example: Change the labels to different classes\n",
        "\n",
        "poisoned_dataset = train_dataset.clone()\n",
        "for i in poisoned_indices:\n",
        "    poisoned_dataset.targets[i] = poisoned_labels[i]\n",
        "\n",
        "poisoned_loader = DataLoader(poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_normal_poisoned = Net().to(device)\n",
        "optimizer_normal_poisoned = optim.SGD(model_normal_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "print('Training Normal Model with Data Poisoning Attack')\n",
        "loss_normal_poisoned = train(model_normal_poisoned, device, poisoned_loader, optimizer_normal_poisoned, criterion, None, epochs=20)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "epsilon = 1.0\n",
        "delta = 1e-5\n",
        "max_norm = 1.0\n",
        "\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Training Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, train_loader, optimizer_federated, criterion, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "print('Training Federated Model with Data Poisoning Attack')\n",
        "loss_federated_poisoned = train(model_federated_poisoned, device, poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_normal, label='Normal Model without Poisoning')\n",
        "plt.plot(epochs, loss_normal_poisoned, label='Data Poisoning Attack on Normal Model')\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned, label='Data Poisoning Attack on Federated Model (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecEWbe1vyTYe",
        "outputId": "b0b63568-6eb5-4feb-d6fd-2f3730a7bee0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opacus in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.0.1+cu118)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.10.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->opacus) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->opacus) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->opacus) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->opacus) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install opacus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "lpWfPpctzU_g",
        "outputId": "f88bb5b3-4f4b-4363-e05a-2aa10ab7eaef"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-62cce4993d52>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopacus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPerSampleGradientClipper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrivacyEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Define the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'PerSampleGradientClipper' from 'opacus' (/usr/local/lib/python3.10/dist-packages/opacus/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torchdp import PerSampleGradientClipper, PrivacyEngine\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)  # Example architecture with a single fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, clipper, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            clipper(model)\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print('Epoch {}: Loss = {}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the normal model\n",
        "per_sample_grad_clipper = PerSampleGradientClipper(1.0)\n",
        "privacy_engine_normal = PrivacyEngine(\n",
        "    model_normal,\n",
        "    per_sample_grad_clipper,\n",
        "    target_delta=1e-5,\n",
        "    epochs=20,\n",
        "    sample_size=len(train_dataset),\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_normal.attach(optimizer_normal)\n",
        "\n",
        "print('Normal Model without Data Poisoning Attack')\n",
        "loss_normal = train(model_normal, device, train_loader, optimizer_normal, criterion, per_sample_grad_clipper, privacy_engine_normal, epochs=20)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_poisoned = Net().to(device)\n",
        "optimizer_poisoned = optim.SGD(model_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the normal model with data poisoning attack\n",
        "privacy_engine_poisoned = PrivacyEngine(\n",
        "    model_poisoned,\n",
        "    per_sample_grad_clipper,\n",
        "    target_delta=1e-5,\n",
        "    epochs=20,\n",
        "    sample_size=len(train_dataset),\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_poisoned.attach(optimizer_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Normal Model')\n",
        "loss_poisoned = train(model_poisoned, device, train_loader, optimizer_poisoned, criterion, per_sample_grad_clipper, privacy_engine_poisoned, epochs=20)\n",
        "\n",
        "# Set up the federated model without data poisoning attack (assuming 2 clients)\n",
        "client1_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_dataset = train_dataset  # Example: Client 2 also has the original MNIST dataset\n",
        "\n",
        "client1_loader = torch.utils.data.DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = torch.utils.data.DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    per_sample_grad_clipper,\n",
        "    target_delta=1e-5,\n",
        "    epochs=20,\n",
        "    sample_size=len(train_dataset),\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, client1_loader, optimizer_federated, criterion, per_sample_grad_clipper, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Set up the federated model with data poisoning attack (assuming 2 clients)\n",
        "client1_poisoned_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_poisoned_dataset = train_dataset  # Example: Client 2 has the poisoned MNIST dataset\n",
        "\n",
        "client1_poisoned_loader = torch.utils.data.DataLoader(client1_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_poisoned_loader = torch.utils.data.DataLoader(client2_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    per_sample_grad_clipper,\n",
        "    target_delta=1e-5,\n",
        "    epochs=20,\n",
        "    sample_size=len(train_dataset),\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned_client1 = train(model_federated_poisoned, device, client1_poisoned_loader, optimizer_federated_poisoned, criterion, per_sample_grad_clipper, privacy_engine_federated_poisoned, epochs=20)\n",
        "loss_federated_poisoned_client2 = train(model_federated_poisoned, device, client2_poisoned_loader, optimizer_federated_poisoned, criterion, per_sample_grad_clipper, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_normal, label='Normal Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_poisoned, label='Data Poisoning Attack on Normal Model (DP)')\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client1, label='Data Poisoning Attack on Federated Model (Client 1) (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client2, label='Data Poisoning Attack on Federated Model (Client 2) (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "BFAfL2br1jar",
        "outputId": "aa420cbb-e67d-4830-9d32-71577ae4a8d5"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1f1b78741651>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchdp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPerSampleGradientClipper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrivacyEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Define the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchdp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torchdp import PerSampleGradientClipper, PrivacyEngine\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)  # Example architecture with a single fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, clipper, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            clipper(model)\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print('Epoch {}: Loss = {}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the normal model\n",
        "per_sample_grad_clipper = PerSampleGradientClipper(1.0)\n",
        "privacy_engine_normal = PrivacyEngine(\n",
        "    model_normal,\n",
        "    per_sample_grad_clipper,\n",
        "    target_delta=1e-5,\n",
        "    epochs=20,\n",
        "    sample_size=len(train_dataset),\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_normal.attach(optimizer_normal)\n",
        "\n",
        "print('Normal Model without Data Poisoning Attack')\n",
        "loss_normal = train(model_normal, device, train_loader, optimizer_normal, criterion, per_sample_grad_clipper, privacy_engine_normal, epochs=20)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_poisoned = Net().to(device)\n",
        "optimizer_poisoned = optim.SGD(model_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the normal model with data poisoning attack\n",
        "privacy_engine_poisoned = PrivacyEngine(\n",
        "    model_poisoned,\n",
        "    per_sample_grad_clipper,\n",
        "    target_delta=1e-5,\n",
        "    epochs=20,\n",
        "    sample_size=len(train_dataset),\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_poisoned.attach(optimizer_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Normal Model')\n",
        "loss_poisoned = train(model_poisoned, device, train_loader, optimizer_poisoned, criterion, per_sample_grad_clipper, privacy_engine_poisoned, epochs=20)\n",
        "\n",
        "# Set up the federated model without data poisoning attack (assuming 2 clients)\n",
        "client1_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_dataset = train_dataset  # Example: Client 2 also has the original MNIST dataset\n",
        "\n",
        "client1_loader = torch.utils.data.DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = torch.utils.data.DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    per_sample_grad_clipper,\n",
        "    target_delta=1e-5,\n",
        "    epochs=20,\n",
        "    sample_size=len(train_dataset),\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, client1_loader, optimizer_federated, criterion, per_sample_grad_clipper, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Set up the federated model with data poisoning attack (assuming 2 clients)\n",
        "client1_poisoned_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_poisoned_dataset = train_dataset  # Example: Client 2 has the poisoned MNIST dataset\n",
        "\n",
        "client1_poisoned_loader = torch.utils.data.DataLoader(client1_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_poisoned_loader = torch.utils.data.DataLoader(client2_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    per_sample_grad_clipper,\n",
        "    target_delta=1e-5,\n",
        "    epochs=20,\n",
        "    sample_size=len(train_dataset),\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned_client1 = train(model_federated_poisoned, device, client1_poisoned_loader, optimizer_federated_poisoned, criterion, per_sample_grad_clipper, privacy_engine_federated_poisoned, epochs=20)\n",
        "loss_federated_poisoned_client2 = train(model_federated_poisoned, device, client2_poisoned_loader, optimizer_federated_poisoned, criterion, per_sample_grad_clipper, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_normal, label='Normal Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_poisoned, label='Data Poisoning Attack on Normal Model (DP)')\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client1, label='Data Poisoning Attack on Federated Model (Client 1) (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client2, label='Data Poisoning Attack on Federated Model (Client 2) (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNl4AELNz6ys",
        "outputId": "dbf5b525-c06c-4d51-a606-bf347b0ffd2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torchprivacy (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchprivacy\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install torchprivacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_jsbTMtzIX-",
        "outputId": "24b905da-59bb-4f1a-fc04-776ab7e5c773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch-dp (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch-dp\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install torch-dp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTuUCX_X-Zdn",
        "outputId": "eebaa375-36de-4f73-a23d-10a8a2de2585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opacus\n",
            "  Downloading opacus-1.4.0-py3-none-any.whl (224 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/224.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m215.0/224.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.0.1+cu118)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.10.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->opacus) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->opacus) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->opacus) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->opacus) (1.3.0)\n",
            "Installing collected packages: opacus\n",
            "Successfully installed opacus-1.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install opacus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "wfYyaMB4-d8C",
        "outputId": "f1eb99dc-7e71-44fb-9f83-5974971cb7f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 101776776.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 18553483.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 26525311.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4760252.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-187c0eb733af>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Apply differential privacy to the normal model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m privacy_engine_normal = PrivacyEngine(\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mmodel_normal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PrivacyEngine.__init__() got an unexpected keyword argument 'sample_rate'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)  # Example architecture with a single fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print('Epoch {}: Loss = {}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the normal model\n",
        "privacy_engine_normal = PrivacyEngine(\n",
        "    model_normal,\n",
        "    sample_rate=1.0,\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_normal.attach(optimizer_normal)\n",
        "\n",
        "print('Normal Model without Data Poisoning Attack')\n",
        "loss_normal = train(model_normal, device, train_loader, optimizer_normal, criterion, privacy_engine_normal, epochs=20)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_poisoned = Net().to(device)\n",
        "optimizer_poisoned = optim.SGD(model_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the normal model with data poisoning attack\n",
        "privacy_engine_poisoned = PrivacyEngine(\n",
        "    model_poisoned,\n",
        "    sample_rate=1.0,\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_poisoned.attach(optimizer_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Normal Model')\n",
        "loss_poisoned = train(model_poisoned, device, train_loader, optimizer_poisoned, criterion, privacy_engine_poisoned, epochs=20)\n",
        "\n",
        "# Set up the federated model without data poisoning attack (assuming 2 clients)\n",
        "client1_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_dataset = train_dataset  # Example: Client 2 also has the original MNIST dataset\n",
        "\n",
        "client1_loader = torch.utils.data.DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = torch.utils.data.DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    sample_rate=1.0,\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, client1_loader, optimizer_federated, criterion, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Set up the federated model with data poisoning attack (assuming 2 clients)\n",
        "client1_poisoned_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_poisoned_dataset = train_dataset  # Example: Client 2 has the poisoned MNIST dataset\n",
        "\n",
        "client1_poisoned_loader = torch.utils.data.DataLoader(client1_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_poisoned_loader = torch.utils.data.DataLoader(client2_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    sample_rate=1.0,\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned_client1 = train(model_federated_poisoned, device, client1_poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "loss_federated_poisoned_client2 = train(model_federated_poisoned, device, client2_poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_normal, label='Normal Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_poisoned, label='Data Poisoning Attack on Normal Model (DP)')\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client1, label='Data Poisoning Attack on Federated Model (Client 1) (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client2, label='Data Poisoning Attack on Federated Model (Client 2) (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "U-wqV-Nd_PrY",
        "outputId": "ee1c3ecf-2e19-4e57-bb03-0fe211a29c87"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-bccc580036ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtarget_epsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtarget_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'epsilon' is not defined"
          ]
        }
      ],
      "source": [
        "privacy_engine_normal = PrivacyEngine(\n",
        "    model_normal,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Gd-KXUkRANO8",
        "outputId": "fe78b1e8-4e5c-4148-ee3e-67ce6a52ed75"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2ad57740a892>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m  \u001b[0;31m# Maximum gradient norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m privacy_engine_normal = PrivacyEngine(\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mmodel_normal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PrivacyEngine.__init__() got an unexpected keyword argument 'batch_size'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)  # Example architecture with a single fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print('Epoch {}: Loss = {}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the normal model\n",
        "epsilon = 1.0  # Privacy parameter epsilon\n",
        "delta = 1e-5  # Privacy parameter delta\n",
        "max_norm = 1.0  # Maximum gradient norm\n",
        "\n",
        "privacy_engine_normal = PrivacyEngine(\n",
        "    model_normal,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_normal.attach(optimizer_normal)\n",
        "\n",
        "print('Normal Model without Data Poisoning Attack')\n",
        "loss_normal = train(model_normal, device, train_loader, optimizer_normal, criterion, privacy_engine_normal, epochs=20)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_poisoned = Net().to(device)\n",
        "optimizer_poisoned = optim.SGD(model_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the normal model with data poisoning attack\n",
        "privacy_engine_poisoned = PrivacyEngine(\n",
        "    model_poisoned,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_poisoned.attach(optimizer_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Normal Model')\n",
        "loss_poisoned = train(model_poisoned, device, train_loader, optimizer_poisoned, criterion, privacy_engine_poisoned, epochs=20)\n",
        "\n",
        "# Set up the federated model without data poisoning attack (assuming 2 clients)\n",
        "client1_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_dataset = train_dataset  # Example: Client 2 also has the original MNIST dataset\n",
        "\n",
        "client1_loader = torch.utils.data.DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = torch.utils.data.DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, client1_loader, optimizer_federated, criterion, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Set up the federated model with data poisoning attack (assuming 2 clients)\n",
        "client1_poisoned_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_poisoned_dataset = train_dataset  # Example: Client 2 has the poisoned MNIST dataset\n",
        "\n",
        "client1_poisoned_loader = torch.utils.data.DataLoader(client1_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_poisoned_loader = torch.utils.data.DataLoader(client2_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned_client1 = train(model_federated_poisoned, device, client1_poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "loss_federated_poisoned_client2 = train(model_federated_poisoned, device, client2_poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_normal, label='Normal Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_poisoned, label='Data Poisoning Attack on Normal Model (DP)')\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client1, label='Data Poisoning Attack on Federated Model (Client 1) (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client2, label='Data Poisoning Attack on Federated Model (Client 2) (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "14XCAzgHAp5G",
        "outputId": "61c90b38-4147-470c-b821-fc0264149eaf"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ef0e31f70bbf>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopacus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrivacyEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Define the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'opacus'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)  # Example architecture with a single fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print('Epoch {}: Loss = {}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the normal model\n",
        "epsilon = 1.0  # Privacy parameter epsilon\n",
        "delta = 1e-5  # Privacy parameter delta\n",
        "max_norm = 1.0  # Maximum gradient norm\n",
        "\n",
        "privacy_engine_normal = PrivacyEngine(\n",
        "    model_normal,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_normal.attach(optimizer_normal)\n",
        "\n",
        "print('Normal Model without Data Poisoning Attack')\n",
        "loss_normal = train(model_normal, device, train_loader, optimizer_normal, criterion, privacy_engine_normal, epochs=20)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_poisoned = Net().to(device)\n",
        "optimizer_poisoned = optim.SGD(model_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the normal model with data poisoning attack\n",
        "privacy_engine_poisoned = PrivacyEngine(\n",
        "    model_poisoned,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_poisoned.attach(optimizer_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Normal Model')\n",
        "loss_poisoned = train(model_poisoned, device, train_loader, optimizer_poisoned, criterion, privacy_engine_poisoned, epochs=20)\n",
        "\n",
        "# Set up the federated model without data poisoning attack (assuming 2 clients)\n",
        "client1_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_dataset = train_dataset  # Example: Client 2 also has the original MNIST dataset\n",
        "\n",
        "client1_loader = torch.utils.data.DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = torch.utils.data.DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, client1_loader, optimizer_federated, criterion, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Set up the federated model with data poisoning attack (assuming 2 clients)\n",
        "client1_poisoned_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_poisoned_dataset = train_dataset  # Example: Client 2 has the poisoned MNIST dataset\n",
        "\n",
        "client1_poisoned_loader = torch.utils.data.DataLoader(client1_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_poisoned_loader = torch.utils.data.DataLoader(client2_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned_client1 = train(model_federated_poisoned, device, client1_poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "loss_federated_poisoned_client2 = train(model_federated_poisoned, device, client2_poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_normal, label='Normal Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_poisoned, label='Data Poisoning Attack on Normal Model (DP)')\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client1, label='Data Poisoning Attack on Federated Model (Client 1) (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client2, label='Data Poisoning Attack on Federated Model (Client 2) (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "papAixF7BqlV",
        "outputId": "562e0f98-8848-4dd2-f4ca-3ecd3ffc2343"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-04cf8d176c53>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m  \u001b[0;31m# Maximum gradient norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m privacy_engine_normal = PrivacyEngine(\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mmodel_normal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PrivacyEngine.__init__() got an unexpected keyword argument 'batch_size'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)  # Example architecture with a single fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print('Epoch {}: Loss = {}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the normal model\n",
        "epsilon = 1.0  # Privacy parameter epsilon\n",
        "delta = 1e-5  # Privacy parameter delta\n",
        "max_norm = 1.0  # Maximum gradient norm\n",
        "\n",
        "privacy_engine_normal = PrivacyEngine(\n",
        "    model_normal,\n",
        "    batch_size=batch_size,\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_normal.attach(optimizer_normal)\n",
        "\n",
        "print('Normal Model without Data Poisoning Attack')\n",
        "loss_normal = train(model_normal, device, train_loader, optimizer_normal, criterion, privacy_engine_normal, epochs=20)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_poisoned = Net().to(device)\n",
        "optimizer_poisoned = optim.SGD(model_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the normal model with data poisoning attack\n",
        "privacy_engine_poisoned = PrivacyEngine(\n",
        "    model_poisoned,\n",
        "    batch_size=batch_size,\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_poisoned.attach(optimizer_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Normal Model')\n",
        "loss_poisoned = train(model_poisoned, device, train_loader, optimizer_poisoned, criterion, privacy_engine_poisoned, epochs=20)\n",
        "\n",
        "# Set up the federated model without data poisoning attack (assuming 2 clients)\n",
        "client1_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_dataset = train_dataset  # Example: Client 2 also has the original MNIST dataset\n",
        "\n",
        "client1_loader = torch.utils.data.DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = torch.utils.data.DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    batch_size=batch_size,\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, client1_loader, optimizer_federated, criterion, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Set up the federated model with data poisoning attack (assuming 2 clients)\n",
        "client1_poisoned_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_poisoned_dataset = train_dataset  # Example: Client 2 has the poisoned MNIST dataset\n",
        "\n",
        "client1_poisoned_loader = torch.utils.data.DataLoader(client1_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_poisoned_loader = torch.utils.data.DataLoader(client2_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    batch_size=batch_size,\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned_client1 = train(model_federated_poisoned, device, client1_poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "loss_federated_poisoned_client2 = train(model_federated_poisoned, device, client2_poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_normal, label='Normal Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_poisoned, label='Data Poisoning Attack on Normal Model (DP)')\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client1, label='Data Poisoning Attack on Federated Model (Client 1) (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client2, label='Data Poisoning Attack on Federated Model (Client 2) (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "vI6KBAX_DAx8",
        "outputId": "d0ed7db2-c400-46bb-f00f-0445330ba6a1"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-113d521cc447>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m  \u001b[0;31m# Maximum gradient norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m privacy_engine_normal = PrivacyEngine(\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mmodel_normal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mper_sample_grad_clip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Set a value for per-sample gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PrivacyEngine.__init__() got an unexpected keyword argument 'per_sample_grad_clip'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)  # Example architecture with a single fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print('Epoch {}: Loss = {}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the normal model\n",
        "epsilon = 1.0  # Privacy parameter epsilon\n",
        "delta = 1e-5  # Privacy parameter delta\n",
        "max_norm = 1.0  # Maximum gradient norm\n",
        "\n",
        "privacy_engine_normal = PrivacyEngine(\n",
        "    model_normal,\n",
        "    per_sample_grad_clip=0.1,  # Set a value for per-sample gradient clipping\n",
        "    noise_multiplier=1.3,  # Set the desired noise multiplier\n",
        "    max_grad_norm=max_norm,\n",
        "    target_delta=delta,\n",
        "    target_epsilon=epsilon,\n",
        ")\n",
        "privacy_engine_normal.attach(optimizer_normal)\n",
        "\n",
        "print('Normal Model without Data Poisoning Attack')\n",
        "loss_normal = train(model_normal, device, train_loader, optimizer_normal, criterion, privacy_engine_normal, epochs=20)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_poisoned = Net().to(device)\n",
        "optimizer_poisoned = optim.SGD(model_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the normal model with data poisoning attack\n",
        "privacy_engine_poisoned = PrivacyEngine(\n",
        "    model_poisoned,\n",
        "    per_sample_grad_clip=0.1,  # Set a value for per-sample gradient clipping\n",
        "    noise_multiplier=1.3,  # Set the desired noise multiplier\n",
        "    max_grad_norm=max_norm,\n",
        "    target_delta=delta,\n",
        "    target_epsilon=epsilon,\n",
        ")\n",
        "privacy_engine_poisoned.attach(optimizer_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Normal Model')\n",
        "loss_poisoned = train(model_poisoned, device, train_loader, optimizer_poisoned, criterion, privacy_engine_poisoned, epochs=20)\n",
        "\n",
        "# Set up the federated model without data poisoning attack (assuming 2 clients)\n",
        "client1_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_dataset = train_dataset  # Example: Client 2 also has the original MNIST dataset\n",
        "\n",
        "client1_loader = torch.utils.data.DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = torch.utils.data.DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    per_sample_grad_clip=0.1,  # Set a value for per-sample gradient clipping\n",
        "    noise_multiplier=1.3,  # Set the desired noise multiplier\n",
        "    max_grad_norm=max_norm,\n",
        "    target_delta=delta,\n",
        "    target_epsilon=epsilon,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, client1_loader, optimizer_federated, criterion, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Set up the federated model with data poisoning attack (assuming 2 clients)\n",
        "client1_poisoned_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_poisoned_dataset = train_dataset  # Example: Client 2 has the poisoned MNIST dataset\n",
        "\n",
        "client1_poisoned_loader = torch.utils.data.DataLoader(client1_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_poisoned_loader = torch.utils.data.DataLoader(client2_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    per_sample_grad_clip=0.1,  # Set a value for per-sample gradient clipping\n",
        "    noise_multiplier=1.3,  # Set the desired noise multiplier\n",
        "    max_grad_norm=max_norm,\n",
        "    target_delta=delta,\n",
        "    target_epsilon=epsilon,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned_client1 = train(model_federated_poisoned, device, client1_poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "loss_federated_poisoned_client2 = train(model_federated_poisoned, device, client2_poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_normal, label='Normal Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_poisoned, label='Data Poisoning Attack on Normal Model (DP)')\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client1, label='Data Poisoning Attack on Federated Model (Client 1) (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client2, label='Data Poisoning Attack on Federated Model (Client 2) (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "jJ8PDgwIEkyx",
        "outputId": "4f54df6c-9e75-43c7-9a42-c84d69870f2a"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7b499f883e72>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m  \u001b[0;31m# Maximum gradient norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m privacy_engine_normal = PrivacyEngine(\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mmodel_normal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mclip_per_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Set a value for per-layer gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PrivacyEngine.__init__() got an unexpected keyword argument 'clip_per_layer'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)  # Example architecture with a single fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print('Epoch {}: Loss = {}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the normal model\n",
        "epsilon = 1.0  # Privacy parameter epsilon\n",
        "delta = 1e-5  # Privacy parameter delta\n",
        "max_norm = 1.0  # Maximum gradient norm\n",
        "\n",
        "privacy_engine_normal = PrivacyEngine(\n",
        "    model_normal,\n",
        "    clip_per_layer=0.1,  # Set a value for per-layer gradient clipping\n",
        "    noise_multiplier=1.3,  # Set the desired noise multiplier\n",
        "    max_grad_norm=max_norm,\n",
        "    target_delta=delta,\n",
        "    target_epsilon=epsilon,\n",
        ")\n",
        "privacy_engine_normal.attach(optimizer_normal)\n",
        "\n",
        "print('Normal Model without Data Poisoning Attack')\n",
        "loss_normal = train(model_normal, device, train_loader, optimizer_normal, criterion, privacy_engine_normal, epochs=20)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_poisoned = Net().to(device)\n",
        "optimizer_poisoned = optim.SGD(model_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the normal model with data poisoning attack\n",
        "privacy_engine_poisoned = PrivacyEngine(\n",
        "    model_poisoned,\n",
        "    clip_per_layer=0.1,  # Set a value for per-layer gradient clipping\n",
        "    noise_multiplier=1.3,  # Set the desired noise multiplier\n",
        "    max_grad_norm=max_norm,\n",
        "    target_delta=delta,\n",
        "    target_epsilon=epsilon,\n",
        ")\n",
        "privacy_engine_poisoned.attach(optimizer_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Normal Model')\n",
        "loss_poisoned = train(model_poisoned, device, train_loader, optimizer_poisoned, criterion, privacy_engine_poisoned, epochs=20)\n",
        "\n",
        "# Set up the federated model without data poisoning attack (assuming 2 clients)\n",
        "client1_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_dataset = train_dataset  # Example: Client 2 also has the original MNIST dataset\n",
        "\n",
        "client1_loader = torch.utils.data.DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = torch.utils.data.DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    clip_per_layer=0.1,  # Set a value for per-layer gradient clipping\n",
        "    noise_multiplier=1.3,  # Set the desired noise multiplier\n",
        "    max_grad_norm=max_norm,\n",
        "    target_delta=delta,\n",
        "    target_epsilon=epsilon,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, client1_loader, optimizer_federated, criterion, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Set up the federated model with data poisoning attack (assuming 2 clients)\n",
        "client1_poisoned_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_poisoned_dataset = train_dataset  # Example: Client 2 has the poisoned MNIST dataset\n",
        "\n",
        "client1_poisoned_loader = torch.utils.data.DataLoader(client1_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_poisoned_loader = torch.utils.data.DataLoader(client2_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    clip_per_layer=0.1,  # Set a value for per-layer gradient clipping\n",
        "    noise_multiplier=1.3,  # Set the desired noise multiplier\n",
        "    max_grad_norm=max_norm,\n",
        "    target_delta=delta,\n",
        "    target_epsilon=epsilon,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned_client1 = train(model_federated_poisoned, device, client1_poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "loss_federated_poisoned_client2 = train(model_federated_poisoned, device, client2_poisoned_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_normal, label='Normal Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_poisoned, label='Data Poisoning Attack on Normal Model (DP)')\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client1, label='Data Poisoning Attack on Federated Model (Client 1) (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client2, label='Data Poisoning Attack on Federated Model (Client 2) (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "9Df6LxiLHBKH",
        "outputId": "5e188920-da93-4273-8d65-570ec3af58a3"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3e99c93aee08>\u001b[0m in \u001b[0;36m<cell line: 82>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m privacy_engine_federated = PrivacyEngine(\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mmodel_federated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PrivacyEngine.__init__() got an unexpected keyword argument 'batch_size'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from opacus import PrivacyEngine\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define a custom dataset class for the poisoned data\n",
        "class PoisonedDataset(Dataset):\n",
        "    def __init__(self, dataset, poison_indices, poison_labels):\n",
        "        self.dataset = dataset\n",
        "        self.poison_indices = poison_indices\n",
        "        self.poison_labels = poison_labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index in self.poison_indices:\n",
        "            _, target = self.dataset[index]\n",
        "            target = self.poison_labels[index]\n",
        "            return self.dataset[index][0], target\n",
        "        else:\n",
        "            return self.dataset[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print(f'Epoch {epoch + 1}: Loss = {running_loss / len(train_loader):.4f}')\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "epsilon = 1.0\n",
        "delta = 1e-5\n",
        "max_norm = 1.0\n",
        "\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, train_loader, optimizer_federated, criterion, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Prepare the poisoned dataset for the data poisoning attack on the federated model\n",
        "poisoned_indices = [0, 1, 2, 3, 4]  # Example: Poison the first 5 samples\n",
        "poisoned_labels = [5, 0, 1, 2, 3]  # Example: Change the labels to different classes\n",
        "\n",
        "client1_dataset = train_dataset\n",
        "client2_dataset = PoisonedDataset(train_dataset, poisoned_indices, poisoned_labels)\n",
        "\n",
        "client1_loader = DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned = train(model_federated_poisoned, device, client2_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned, label='Data Poisoning Attack on Federated Model (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "RvDmjHVsH9rq",
        "outputId": "12431530-f7df-40f0-94c1-cf99be10cc80"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-eb8c2725c235>\u001b[0m in \u001b[0;36m<cell line: 82>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m privacy_engine_federated = PrivacyEngine(\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mmodel_federated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PrivacyEngine.__init__() got an unexpected keyword argument 'sample_rate'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from opacus import PrivacyEngine\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define a custom dataset class for the poisoned data\n",
        "class PoisonedDataset(Dataset):\n",
        "    def __init__(self, dataset, poison_indices, poison_labels):\n",
        "        self.dataset = dataset\n",
        "        self.poison_indices = poison_indices\n",
        "        self.poison_labels = poison_labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index in self.poison_indices:\n",
        "            _, target = self.dataset[index]\n",
        "            target = self.poison_labels[index]\n",
        "            return self.dataset[index][0], target\n",
        "        else:\n",
        "            return self.dataset[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print(f'Epoch {epoch + 1}: Loss = {running_loss / len(train_loader):.4f}')\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "epsilon = 1.0\n",
        "delta = 1e-5\n",
        "max_norm = 1.0\n",
        "\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    sample_rate=len(train_loader.dataset) / len(train_dataset),\n",
        "    alphas=[1 + x / 10.0 for x in range(1, 100)],\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=max_norm,\n",
        "    target_delta=delta,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, train_loader, optimizer_federated, criterion, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Prepare the poisoned dataset for the data poisoning attack on the federated model\n",
        "poisoned_indices = [0, 1, 2, 3, 4]  # Example: Poison the first 5 samples\n",
        "poisoned_labels = [5, 0, 1, 2, 3]  # Example: Change the labels to different classes\n",
        "\n",
        "client1_dataset = train_dataset\n",
        "client2_dataset = PoisonedDataset(train_dataset, poisoned_indices, poisoned_labels)\n",
        "\n",
        "client1_loader = DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    sample_rate=len(client2_loader.dataset) / len(train_dataset),\n",
        "    alphas=[1 + x / 10.0 for x in range(1, 100)],\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=max_norm,\n",
        "    target_delta=delta,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned = train(model_federated_poisoned, device, client2_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned, label='Data Poisoning Attack on Federated Model (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "iaN2JWbSIz7n",
        "outputId": "bf93b42e-dc06-4cbb-ef5d-dd771ff3924d"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6668a7cbf40b>\u001b[0m in \u001b[0;36m<cell line: 82>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m privacy_engine_federated = PrivacyEngine(\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mmodel_federated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PrivacyEngine.__init__() got an unexpected keyword argument 'batch_size'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from opacus import PrivacyEngine\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define a custom dataset class for the poisoned data\n",
        "class PoisonedDataset(Dataset):\n",
        "    def __init__(self, dataset, poison_indices, poison_labels):\n",
        "        self.dataset = dataset\n",
        "        self.poison_indices = poison_indices\n",
        "        self.poison_labels = poison_labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index in self.poison_indices:\n",
        "            _, target = self.dataset[index]\n",
        "            target = self.poison_labels[index]\n",
        "            return self.dataset[index][0], target\n",
        "        else:\n",
        "            return self.dataset[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print(f'Epoch {epoch + 1}: Loss = {running_loss / len(train_loader):.4f}')\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "epsilon = 1.0\n",
        "delta = 1e-5\n",
        "max_norm = 1.0\n",
        "\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, train_loader, optimizer_federated, criterion, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Prepare the poisoned dataset for the data poisoning attack on the federated model\n",
        "poisoned_indices = [0, 1, 2, 3, 4]  # Example: Poison the first 5 samples\n",
        "poisoned_labels = [5, 0, 1, 2, 3]  # Example: Change the labels to different classes\n",
        "\n",
        "client1_dataset = train_dataset\n",
        "client2_dataset = PoisonedDataset(train_dataset, poisoned_indices, poisoned_labels)\n",
        "\n",
        "client1_loader = DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned = train(model_federated_poisoned, device, client2_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned, label='Data Poisoning Attack on Federated Model (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzEhvcKxL10N",
        "outputId": "e4ed414f-481e-4638-db9a-b664a2a1b295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "ozNWRT93L8LP",
        "outputId": "5a8c8197-4edd-477b-896d-e964162c7428"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3e99c93aee08>\u001b[0m in \u001b[0;36m<cell line: 82>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m privacy_engine_federated = PrivacyEngine(\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mmodel_federated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PrivacyEngine.__init__() got an unexpected keyword argument 'batch_size'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from opacus import PrivacyEngine\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define a custom dataset class for the poisoned data\n",
        "class PoisonedDataset(Dataset):\n",
        "    def __init__(self, dataset, poison_indices, poison_labels):\n",
        "        self.dataset = dataset\n",
        "        self.poison_indices = poison_indices\n",
        "        self.poison_labels = poison_labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index in self.poison_indices:\n",
        "            _, target = self.dataset[index]\n",
        "            target = self.poison_labels[index]\n",
        "            return self.dataset[index][0], target\n",
        "        else:\n",
        "            return self.dataset[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print(f'Epoch {epoch + 1}: Loss = {running_loss / len(train_loader):.4f}')\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "epsilon = 1.0\n",
        "delta = 1e-5\n",
        "max_norm = 1.0\n",
        "\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, train_loader, optimizer_federated, criterion, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Prepare the poisoned dataset for the data poisoning attack on the federated model\n",
        "poisoned_indices = [0, 1, 2, 3, 4]  # Example: Poison the first 5 samples\n",
        "poisoned_labels = [5, 0, 1, 2, 3]  # Example: Change the labels to different classes\n",
        "\n",
        "client1_dataset = train_dataset\n",
        "client2_dataset = PoisonedDataset(train_dataset, poisoned_indices, poisoned_labels)\n",
        "\n",
        "client1_loader = DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=len(train_dataset),\n",
        "    target_epsilon=epsilon,\n",
        "    target_delta=delta,\n",
        "    max_grad_norm=max_norm,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned = train(model_federated_poisoned, device, client2_loader, optimizer_federated_poisoned, criterion, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned, label='Data Poisoning Attack on Federated Model (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_ntntoNMsuo",
        "outputId": "ba7b10b5-7c41-4e0e-bce8-108c62e3e467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-dp\n",
            "  Using cached pytorch_dp-0.1b1-py3-none-any.whl (50 kB)\n",
            "Collecting attrs==19.3.0 (from pytorch-dp)\n",
            "  Using cached attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting bleach==3.1.5 (from pytorch-dp)\n",
            "  Using cached bleach-3.1.5-py2.py3-none-any.whl (151 kB)\n",
            "Collecting certifi==2020.4.5.1 (from pytorch-dp)\n",
            "  Using cached certifi-2020.4.5.1-py2.py3-none-any.whl (157 kB)\n",
            "Collecting chardet==3.0.4 (from pytorch-dp)\n",
            "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "Requirement already satisfied: docutils==0.16 in /usr/local/lib/python3.10/dist-packages (from pytorch-dp) (0.16)\n",
            "Collecting future==0.18.2 (from pytorch-dp)\n",
            "  Using cached future-0.18.2.tar.gz (829 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting idna==2.9 (from pytorch-dp)\n",
            "  Using cached idna-2.9-py2.py3-none-any.whl (58 kB)\n",
            "Collecting importlib-metadata==1.6.0 (from pytorch-dp)\n",
            "  Using cached importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\n",
            "Collecting keyring==21.2.1 (from pytorch-dp)\n",
            "  Using cached keyring-21.2.1-py3-none-any.whl (31 kB)\n",
            "Collecting more-itertools==8.3.0 (from pytorch-dp)\n",
            "  Using cached more_itertools-8.3.0-py3-none-any.whl (44 kB)\n",
            "Collecting numpy==1.18.4 (from pytorch-dp)\n",
            "  Using cached numpy-1.18.4.zip (5.4 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging==20.4 (from pytorch-dp)\n",
            "  Using cached packaging-20.4-py2.py3-none-any.whl (37 kB)\n",
            "Collecting Pillow==7.1.2 (from pytorch-dp)\n",
            "  Using cached Pillow-7.1.2.tar.gz (38.9 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pkginfo==1.5.0.1 (from pytorch-dp)\n",
            "  Using cached pkginfo-1.5.0.1-py2.py3-none-any.whl (25 kB)\n",
            "Collecting pluggy==0.13.1 (from pytorch-dp)\n",
            "  Using cached pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting py==1.8.1 (from pytorch-dp)\n",
            "  Using cached py-1.8.1-py2.py3-none-any.whl (83 kB)\n",
            "Collecting Pygments==2.6.1 (from pytorch-dp)\n",
            "  Using cached Pygments-2.6.1-py3-none-any.whl (914 kB)\n",
            "Collecting pyparsing==2.4.7 (from pytorch-dp)\n",
            "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "Collecting pytest==5.4.2 (from pytorch-dp)\n",
            "  Using cached pytest-5.4.2-py3-none-any.whl (247 kB)\n",
            "Collecting readme-renderer==26.0 (from pytorch-dp)\n",
            "  Using cached readme_renderer-26.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting requests==2.23.0 (from pytorch-dp)\n",
            "  Using cached requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
            "Collecting requests-toolbelt==0.9.1 (from pytorch-dp)\n",
            "  Using cached requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "Collecting scipy==1.4.1 (from pytorch-dp)\n",
            "  Using cached scipy-1.4.1.tar.gz (24.6 MB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "pip install pytorch-dp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ROd1aeHeOulN",
        "outputId": "f98b8ce8-4531-42d3-ce2a-d66b28d11aae"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d0e5517c17e7>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorchdp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPerSampleGradientClipper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrivacyEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Define the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorchdp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torchdp import PerSampleGradientClipper, PrivacyEngine\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)  # Example architecture with a single fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, clipper, privacy_engine, epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            clipper(model)\n",
        "            optimizer.step()\n",
        "            privacy_engine.step()\n",
        "            running_loss += loss.item()\n",
        "        losses.append(running_loss / len(train_loader))\n",
        "        print('Epoch {}: Loss = {}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "    return losses\n",
        "\n",
        "# Set up the device and data loaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the normal model without data poisoning attack\n",
        "model_normal = Net().to(device)\n",
        "optimizer_normal = optim.SGD(model_normal.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apply differential privacy to the normal model\n",
        "per_sample_grad_clipper = PerSampleGradientClipper(1.0)\n",
        "privacy_engine_normal = PrivacyEngine(\n",
        "    model_normal,\n",
        "    per_sample_grad_clipper,\n",
        "    target_delta=1e-5,\n",
        "    epochs=20,\n",
        "    sample_size=len(train_dataset),\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_normal.attach(optimizer_normal)\n",
        "\n",
        "print('Normal Model without Data Poisoning Attack')\n",
        "loss_normal = train(model_normal, device, train_loader, optimizer_normal, criterion, per_sample_grad_clipper, privacy_engine_normal, epochs=20)\n",
        "\n",
        "# Train the normal model with data poisoning attack\n",
        "model_poisoned = Net().to(device)\n",
        "optimizer_poisoned = optim.SGD(model_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the normal model with data poisoning attack\n",
        "privacy_engine_poisoned = PrivacyEngine(\n",
        "    model_poisoned,\n",
        "    per_sample_grad_clipper,\n",
        "    target_delta=1e-5,\n",
        "    epochs=20,\n",
        "    sample_size=len(train_dataset),\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_poisoned.attach(optimizer_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Normal Model')\n",
        "loss_poisoned = train(model_poisoned, device, train_loader, optimizer_poisoned, criterion, per_sample_grad_clipper, privacy_engine_poisoned, epochs=20)\n",
        "\n",
        "# Set up the federated model without data poisoning attack (assuming 2 clients)\n",
        "client1_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_dataset = train_dataset  # Example: Client 2 also has the original MNIST dataset\n",
        "\n",
        "client1_loader = torch.utils.data.DataLoader(client1_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_loader = torch.utils.data.DataLoader(client2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model without data poisoning attack\n",
        "model_federated = Net().to(device)\n",
        "optimizer_federated = optim.SGD(model_federated.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model without data poisoning attack\n",
        "privacy_engine_federated = PrivacyEngine(\n",
        "    model_federated,\n",
        "    per_sample_grad_clipper,\n",
        "    target_delta=1e-5,\n",
        "    epochs=20,\n",
        "    sample_size=len(train_dataset),\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_federated.attach(optimizer_federated)\n",
        "\n",
        "print('Federated Model without Data Poisoning Attack')\n",
        "loss_federated = train(model_federated, device, client1_loader, optimizer_federated, criterion, per_sample_grad_clipper, privacy_engine_federated, epochs=20)\n",
        "\n",
        "# Set up the federated model with data poisoning attack (assuming 2 clients)\n",
        "client1_poisoned_dataset = train_dataset  # Example: Client 1 has the original MNIST dataset\n",
        "client2_poisoned_dataset = train_dataset  # Example: Client 2 has the poisoned MNIST dataset\n",
        "\n",
        "client1_poisoned_loader = torch.utils.data.DataLoader(client1_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "client2_poisoned_loader = torch.utils.data.DataLoader(client2_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the federated model with data poisoning attack\n",
        "model_federated_poisoned = Net().to(device)\n",
        "optimizer_federated_poisoned = optim.SGD(model_federated_poisoned.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Apply differential privacy to the federated model with data poisoning attack\n",
        "privacy_engine_federated_poisoned = PrivacyEngine(\n",
        "    model_federated_poisoned,\n",
        "    per_sample_grad_clipper,\n",
        "    target_delta=1e-5,\n",
        "    epochs=20,\n",
        "    sample_size=len(train_dataset),\n",
        "    noise_multiplier=1.3,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "privacy_engine_federated_poisoned.attach(optimizer_federated_poisoned)\n",
        "\n",
        "print('Data Poisoning Attack on Federated Model')\n",
        "loss_federated_poisoned_client1 = train(model_federated_poisoned, device, client1_poisoned_loader, optimizer_federated_poisoned, criterion, per_sample_grad_clipper, privacy_engine_federated_poisoned, epochs=20)\n",
        "loss_federated_poisoned_client2 = train(model_federated_poisoned, device, client2_poisoned_loader, optimizer_federated_poisoned, criterion, per_sample_grad_clipper, privacy_engine_federated_poisoned, epochs=20)\n",
        "\n",
        "# Plot the loss convergence for comparison\n",
        "epochs = range(1, 21)  # Number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_normal, label='Normal Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_poisoned, label='Data Poisoning Attack on Normal Model (DP)')\n",
        "plt.plot(epochs, loss_federated, label='Federated Model without Poisoning (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client1, label='Data Poisoning Attack on Federated Model (Client 1) (DP)')\n",
        "plt.plot(epochs, loss_federated_poisoned_client2, label='Data Poisoning Attack on Federated Model (Client 2) (DP)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Convergence on MNIST Dataset (with Differential Privacy)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Application of FL task\n",
        "from MLModel import *\n",
        "from FLModel import *\n",
        "from utils import *\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "sCsBBkwBfSkG",
        "outputId": "0353a2f7-fd4b-4fd9-9009-14b223cc612a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-05316bce7da5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Application of FL task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mMLModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mFLModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/MLModel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkymatio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mScattering2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMNIST_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kymatio'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/amzn/differential-privacy-bayesian-optimization.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyiPtOJ4gXqj",
        "outputId": "b0d77d65-e113-4b57-ed6d-f35c8cc56359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'differential-privacy-bayesian-optimization'...\n",
            "remote: Enumerating objects: 1572, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 1572 (delta 68), reused 149 (delta 68), pack-reused 1414\u001b[K\n",
            "Receiving objects: 100% (1572/1572), 7.52 MiB | 9.43 MiB/s, done.\n",
            "Resolving deltas: 100% (141/141), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd differential-privacy-bayesian-optimization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HsqcV0wigms",
        "outputId": "c6c0c0e0-915d-490d-9c8a-d83b133dae84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/differential-privacy-bayesian-optimization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DX1uxQaOioGl",
        "outputId": "79a90338-3cad-4f2c-e2e9-4a3f285a7b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.22.0 (from -r requirements.txt (line 1))\n",
            "  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seaborn==0.9.1 (from -r requirements.txt (line 2))\n",
            "  Downloading seaborn-0.9.1-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.4/216.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil==5.6.6 (from -r requirements.txt (line 3))\n",
            "  Downloading psutil-5.6.6.tar.gz (447 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.8/447.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mxnet==1.5.1 (from -r requirements.txt (line 4))\n",
            "  Downloading mxnet-1.5.1-py2.py3-none-manylinux1_x86_64.whl (23.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autodp>=0.1 (from -r requirements.txt (line 5))\n",
            "  Downloading autodp-0.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.0.1+cu118)\n",
            "Collecting gpytorch>=1.4 (from -r requirements.txt (line 7))\n",
            "  Downloading gpytorch-1.11-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botorch>=0.4 (from -r requirements.txt (line 8))\n",
            "  Downloading botorch-0.8.5-py3-none-any.whl (530 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.3/530.3 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.9.1->-r requirements.txt (line 2)) (1.10.1)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.9.1->-r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.9.1->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet==1.5.1->-r requirements.txt (line 4)) (2.27.1)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet==1.5.1->-r requirements.txt (line 4))\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->-r requirements.txt (line 6)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->-r requirements.txt (line 6)) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->-r requirements.txt (line 6)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->-r requirements.txt (line 6)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->-r requirements.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8->-r requirements.txt (line 6)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8->-r requirements.txt (line 6)) (16.0.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch>=1.4->-r requirements.txt (line 7)) (1.2.2)\n",
            "Collecting linear-operator>=0.5.0 (from gpytorch>=1.4->-r requirements.txt (line 7))\n",
            "  Downloading linear_operator-0.5.0-py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.0/173.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from botorch>=0.4->-r requirements.txt (line 8)) (1.0.0)\n",
            "Collecting pyro-ppl>=1.8.4 (from botorch>=0.4->-r requirements.txt (line 8))\n",
            "  Downloading pyro_ppl-1.8.5-py3-none-any.whl (732 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.5/732.5 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpytorch>=1.4 (from -r requirements.txt (line 7))\n",
            "  Downloading gpytorch-1.10-py3-none-any.whl (255 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of botorch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting botorch>=0.4 (from -r requirements.txt (line 8))\n",
            "  Downloading botorch-0.8.4-py3-none-any.whl (530 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.0/530.0 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading botorch-0.8.3-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.8/521.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpytorch>=1.4 (from -r requirements.txt (line 7))\n",
            "  Downloading gpytorch-1.9.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botorch>=0.4 (from -r requirements.txt (line 8))\n",
            "  Downloading botorch-0.8.2-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.0/521.0 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading botorch-0.8.1-py3-none-any.whl (490 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.6/490.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading botorch-0.8.0-py3-none-any.whl (481 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.8/481.8 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpytorch>=1.4 (from -r requirements.txt (line 7))\n",
            "  Downloading gpytorch-1.9.0-py3-none-any.whl (245 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botorch>=0.4 (from -r requirements.txt (line 8))\n",
            "  Downloading botorch-0.7.3-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.6/431.6 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading botorch-0.7.2-py3-none-any.whl (403 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.2/403.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of botorch to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading botorch-0.7.1-py3-none-any.whl (396 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.7/396.7 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading botorch-0.7.0-py3-none-any.whl (391 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.5/391.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jaxtyping>=0.2.9 (from linear-operator>=0.5.0->gpytorch>=1.4->-r requirements.txt (line 7))\n",
            "  Downloading jaxtyping-0.2.20-py3-none-any.whl (24 kB)\n",
            "Collecting typeguard~=2.13.3 (from linear-operator>=0.5.0->gpytorch>=1.4->-r requirements.txt (line 7))\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.17.1->seaborn==0.9.1->-r requirements.txt (line 2)) (2022.7.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch>=0.4->-r requirements.txt (line 8)) (3.3.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch>=0.4->-r requirements.txt (line 8))\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch>=0.4->-r requirements.txt (line 8)) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1->-r requirements.txt (line 4)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1->-r requirements.txt (line 4)) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1->-r requirements.txt (line 4)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1->-r requirements.txt (line 4)) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->-r requirements.txt (line 6)) (2.1.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch>=1.4->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch>=1.4->-r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (1.16.0)\n",
            "Building wheels for collected packages: psutil, autodp\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psutil: filename=psutil-5.6.6-cp310-cp310-linux_x86_64.whl size=267070 sha256=f525c5acb9a9c61a62940707ab56f6a0f1e466d511d7c5dc747f1dafa469c997\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/64/a3/407615c080b6bd28ec2f82e431c0623215690c53aa61bff735\n",
            "  Building wheel for autodp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autodp: filename=autodp-0.2-py3-none-any.whl size=42444 sha256=31ffe7d605875ec06d592e6faad79d7bfe7687b6089579f2ea8b84cda9b2e2b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/58/65/b22c7a93f9650f8c7ce140b5309a5a0563c7119ad6261b3b93\n",
            "Successfully built psutil autodp\n",
            "Installing collected packages: pyro-api, typeguard, psutil, numpy, graphviz, mxnet, jaxtyping, autodp, seaborn, linear-operator, pyro-ppl, gpytorch, botorch\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.1\n",
            "    Uninstalling graphviz-0.20.1:\n",
            "      Successfully uninstalled graphviz-0.20.1\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.12.2\n",
            "    Uninstalling seaborn-0.12.2:\n",
            "      Successfully uninstalled seaborn-0.12.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "librosa 0.10.0.post2 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed autodp-0.2 botorch-0.7.0 gpytorch-1.11 graphviz-0.8.4 jaxtyping-0.2.20 linear-operator-0.5.0 mxnet-1.5.1 numpy-1.22.0 psutil-5.6.6 pyro-api-0.1.2 pyro-ppl-1.8.5 seaborn-0.9.1 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/wenzhu23333/Differential-Privacy-Based-Federated-Learning.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cDFAWtWoXJl",
        "outputId": "f31ed42a-4808-4bc3-98f8-1ced196dca32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Differential-Privacy-Based-Federated-Learning'...\n",
            "remote: Enumerating objects: 429, done.\u001b[K\n",
            "remote: Counting objects: 100% (293/293), done.\u001b[K\n",
            "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
            "remote: Total 429 (delta 141), reused 201 (delta 59), pack-reused 136\u001b[K\n",
            "Receiving objects: 100% (429/429), 51.18 MiB | 4.61 MiB/s, done.\n",
            "Resolving deltas: 100% (212/212), done.\n",
            "Updating files: 100% (140/140), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sudo apt-get update\n",
        "sudo apt-get install python3-pip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "1Pg1_sj0sXjh",
        "outputId": "dfd0003b-9140-4dc7-bba2-01e4f3c5d267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-0a8a59efa7b4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    sudo apt-get update\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Library for computing privacy values for DP-SGD.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "from absl import app\n",
        "from scipy.optimize import bisect\n",
        "\n",
        "from tensorflow_privacy.rdp_accountant import compute_rdp  # pylint: disable=g-import-not-at-top\n",
        "from tensorflow_privacy.rdp_accountant import get_privacy_spent\n",
        "\n",
        "\n",
        "def apply_dp_sgd_analysis(q, sigma, steps, orders, delta):\n",
        "  \"\"\"Compute and print results of DP-SGD analysis.\"\"\"\n",
        "\n",
        "  # compute_rdp requires that sigma be the ratio of the standard deviation of\n",
        "  # the Gaussian noise to the l2-sensitivity of the function to which it is\n",
        "  # added. Hence, sigma here corresponds to the `noise_multiplier` parameter\n",
        "  # in the DP-SGD implementation found in privacy.optimizers.dp_optimizer\n",
        "  rdp = compute_rdp(q, sigma, steps, orders)\n",
        "\n",
        "  eps, _, opt_order = get_privacy_spent(orders, rdp, target_delta=delta)\n",
        "\n",
        "  return eps, opt_order\n",
        "\n",
        "\n",
        "def compute_noise(n, batch_size, target_epsilon, epochs, delta, noise_lbd):\n",
        "  \"\"\"Compute noise based on the given hyperparameters.\"\"\"\n",
        "  q = batch_size / n  # q - the sampling ratio.\n",
        "  if q > 1:\n",
        "    raise app.UsageError('n must be larger than the batch size.')\n",
        "  orders = ([1.25, 1.5, 1.75, 2., 2.25, 2.5, 3., 3.5, 4., 4.5] +\n",
        "            list(range(5, 64)) + [128, 256, 512])\n",
        "  steps = int(math.ceil(epochs * n / batch_size))\n",
        "\n",
        "  init_noise = noise_lbd  # minimum possible noise\n",
        "  init_epsilon, _ = apply_dp_sgd_analysis(q, init_noise, steps, orders, delta)\n",
        "\n",
        "  if init_epsilon < target_epsilon:  # noise_lbd was an overestimate\n",
        "    print('min_noise too large for target epsilon.')\n",
        "    return 0\n",
        "\n",
        "  cur_epsilon = init_epsilon\n",
        "  max_noise, min_noise = init_noise, 0\n",
        "\n",
        "  # doubling to find the right range\n",
        "  while cur_epsilon > target_epsilon:  # until noise is large enough\n",
        "    max_noise, min_noise = max_noise * 2, max_noise\n",
        "    cur_epsilon, _ = apply_dp_sgd_analysis(q, max_noise, steps, orders, delta)\n",
        "\n",
        "  def epsilon_fn(noise):  # should return 0 if guess_epsilon==target_epsilon\n",
        "    guess_epsilon = apply_dp_sgd_analysis(q, noise, steps, orders, delta)[0]\n",
        "    return guess_epsilon - target_epsilon\n",
        "\n",
        "  target_noise = bisect(epsilon_fn, min_noise, max_noise)\n",
        "  print(\n",
        "      'DP-SGD with sampling rate = {:.3g}% and noise_multiplier = {} iterated'\n",
        "      ' over {} steps satisfies'.format(100 * q, target_noise, steps),\n",
        "      end=' ')\n",
        "  print('differential privacy with eps = {:.3g} and delta = {}.'.format(\n",
        "      target_epsilon, delta))\n",
        "  return target_noise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "IUmGBWpdtKiY",
        "outputId": "ef4ecd49-2b45-4b5f-8e8b-74b6933675bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-35e28f3e6dae>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbisect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_privacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdp_accountant\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_rdp\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_privacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdp_accountant\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_privacy_spent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_privacy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySqPQqSgoubg",
        "outputId": "dfa616f9-30cd-44d2-be15-9104ad04b3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.22.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.22.0)\n",
            "Requirement already satisfied: seaborn==0.9.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.9.1)\n",
            "Requirement already satisfied: psutil==5.6.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (5.6.6)\n",
            "Requirement already satisfied: mxnet==1.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: autodp>=0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.2)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.0.1+cu118)\n",
            "Requirement already satisfied: gpytorch>=1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.11)\n",
            "Requirement already satisfied: botorch>=0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.9.1->-r requirements.txt (line 2)) (1.10.1)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.9.1->-r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.9.1->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet==1.5.1->-r requirements.txt (line 4)) (2.27.1)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from mxnet==1.5.1->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->-r requirements.txt (line 6)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->-r requirements.txt (line 6)) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->-r requirements.txt (line 6)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->-r requirements.txt (line 6)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->-r requirements.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8->-r requirements.txt (line 6)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8->-r requirements.txt (line 6)) (16.0.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch>=1.4->-r requirements.txt (line 7)) (1.2.2)\n",
            "Requirement already satisfied: linear-operator>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from gpytorch>=1.4->-r requirements.txt (line 7)) (0.5.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from botorch>=0.4->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: pyro-ppl>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from botorch>=0.4->-r requirements.txt (line 8)) (1.8.5)\n",
            "Requirement already satisfied: jaxtyping>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch>=1.4->-r requirements.txt (line 7)) (0.2.20)\n",
            "Requirement already satisfied: typeguard~=2.13.3 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch>=1.4->-r requirements.txt (line 7)) (2.13.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.17.1->seaborn==0.9.1->-r requirements.txt (line 2)) (2022.7.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.2->botorch>=0.4->-r requirements.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.2->botorch>=0.4->-r requirements.txt (line 8)) (0.1.2)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.2->botorch>=0.4->-r requirements.txt (line 8)) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1->-r requirements.txt (line 4)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1->-r requirements.txt (line 4)) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1->-r requirements.txt (line 4)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1->-r requirements.txt (line 4)) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->-r requirements.txt (line 6)) (2.1.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch>=1.4->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch>=1.4->-r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.5.3->seaborn==0.9.1->-r requirements.txt (line 2)) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gatm6lb6o2h4",
        "outputId": "8969ad89-a1f9-426b-d34d-d9160adf0693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bash: run.sh: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 draw.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK0tnKe0pClw",
        "outputId": "cb4901a8-ad47-4272-f729-dafa8b7a5349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/differential-privacy-bayesian-optimization/draw.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}